\documentclass[12pt]{article}
 
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb}
 
\begin{document}
 
\title{Week 5}
\author{Josh Klontz\\CSE 891}
 
\maketitle
 
The papers this week explore Bayesian inspired approaches to comparing faces.
The first paper is the classic work of Moghaddam et al.\ on ``Bayesian face recognition'' which demonstrates the Mahalanobis distance as more effective than the Euclidean distance for comparing faces.
The second paper, ``Probabilistic Models for Inference about Identity'' by Li et al., suggests learning identity as a latent variable influenced by presentation and noise.
The third paper by Chen et al. titled, ``Bayesian Face Revisited: A Join Formulation'', extends Moghaddam's work by considering a joint model and using the likelihood ratio as the similarity metric.
\par
The seminal work of Moghaddam et al.\ on Bayesian face recognition presents a probabilistic measure of similarity based on a MAP analysis of image differences.
The paper offers several benifits to the computer vision field.
First, the proposed technique is generic and can be used under any image matching scenario involving the difference of two real-valued vectors.
The approach demonstrates improved accuracy and generality arising from the use of the Mahalanobis distance instead of the Euclidean distance.
Second, the resulting similarity score has an interpretable meaning as the probability of a genuine match given equal priors.
Third, the authors demonstrate how the approach can be optimized so the comparison is almost as fast as a Euclidean distance.
\par
While Moghaddam's approach was shown to be effective at modeling expression and lighting, it is less clear that the same technique can be extended to model pose or facial decorations.
The fundamental issue is that incorporating such gross variations as pose and extreme decorations significantly increases the dimensionality of the subspaces, effectively diluting the density models and rendering them ineffective.
Instead, the authors suggest the use of a multiple-model approach for handling these variations.
\par
The fundamental contribution of the work done by Li et al.\ is a model of the form $x_{ij}=f(h_i,w_{ij},\theta)+\epsilon_{ij}$.
Here $x_{ij}$ is the vectorized data from the $j$th image of the $i$th person, $h_i$ is the latent identity variable, $w_{ij}$ is the viewing conditions, $\theta$ is a vector of model parameters, and $\epsilon_{ij}$ is a Gaussian noise term.
The authors then investigate two approaches to computing face similarity by: 1) evaluating the joint probability of probe and gallery images and 2) forming class-conditional predictive distributions.
Both approaches are considered in three increasingly sophisticated models: 1) probabilistic LDA, 2) Mixtures of PLDAs, and 3) Tied PLDA.
\par
There are two primary weaknesses to the paper.
The first is that the proposed approaches lack closed form solutions, though the authors demonstrate Expectation Maximization as an effective parameter learning technique.
The second is that the paper does not leverage modern successes in patch based feature representations, and instead demonstrates results on raw pixel intensity only.
\par
The final work termed ``Bayesian Face Revisited: A Joint Formulation'' offers more accurate matching compared to classical Bayesian face recognition by modeling templates in a joint space rather than modeling the difference between two templates. The key motivation behind to the joint formulation is that it preserves the separability in the original feature space that can be lost by the classical Bayes formulation. Like the previous work, the learned model requires solving an expectation maximization problem which the authors observe to exhibit, ``very good 'convex' properties.'' 
 
\end{document}
